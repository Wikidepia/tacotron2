{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tacotron 2 inference code \n",
    "Edit the variables **checkpoint_path** and **text** to match yours and run the entire code to generate plots of mel outputs, alignments and audio synthesis from the generated mel-spectrogram using Griffin-Lim."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import libraries and setup matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir crust\n",
    "!wget -q \"https://huggingface.co/Uberduck/HiFi-Crust/resolve/main/g_00000000%20(1)\" -O \"crust/g_00000000\" --show-progress\n",
    "!wget -q \"https://huggingface.co/Uberduck/HiFi-Crust/resolve/main/do_00000000\" -O \"crust/do_00000000\" --show-progress\n",
    "!wget -q \"https://raw.githubusercontent.com/jik876/hifi-gan/master/config_v1.json\" -O \"crust/config.json\" --show-progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "import IPython.display as ipd\n",
    "import os\n",
    "import json\n",
    "import sys\n",
    "sys.path.append('hifi-gan/')\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from hparams import create_hparams\n",
    "from model import Tacotron2\n",
    "from layers import TacotronSTFT, STFT\n",
    "from audio_processing import griffin_lim\n",
    "from train import load_model\n",
    "from text import text_to_sequence\n",
    "\n",
    "from env import AttrDict\n",
    "from meldataset import MAX_WAV_VALUE\n",
    "from models import Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data(data, figsize=(16, 4)):\n",
    "    fig, axes = plt.subplots(1, len(data), figsize=figsize)\n",
    "    for i in range(len(data)):\n",
    "        axes[i].imshow(data[i], aspect='auto', origin='lower', \n",
    "                       interpolation='none')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup hparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = create_hparams()\n",
    "hparams.sampling_rate = 22050"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load model from checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\"\n",
    "checkpoint_path = \"outdir/checkpoint_0\"\n",
    "model = load_model(hparams, device=\"cpu\")\n",
    "model.load_state_dict(torch.load(checkpoint_path, map_location=device)['state_dict'])\n",
    "_ = model.eval().cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(model.parameters()).device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load HiFi-GAN for mel2audio synthesis and denoiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_file = \"crust/g_00000000\"\n",
    "config_file = os.path.join(os.path.split(checkpoint_file)[0], \"config.json\")\n",
    "with open(config_file) as f:\n",
    "    data = f.read()\n",
    "\n",
    "json_config = json.loads(data)\n",
    "attr_dict = AttrDict(json_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator(attr_dict).to(device)\n",
    "checkpoint_dict = torch.load(checkpoint_file, map_location=device)\n",
    "generator.load_state_dict(checkpoint_dict[\"generator\"])\n",
    "generator.eval()\n",
    "generator.remove_weight_norm()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare text input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from g2p_id import G2P\n",
    "\n",
    "def g2p_post(text):\n",
    "    text = text.replace(\"ˈ\", \"\")\n",
    "    text = text.replace(\"ɛ\", \"e\")\n",
    "    text = text.replace(\"ɔ\", \"o\")\n",
    "    text = text.replace(\"ɪ\", \"i\")\n",
    "    text = text.replace(\"ʊ\", \"u\")\n",
    "    return text.lower()\n",
    "\n",
    "g2p = G2P()\n",
    "text = \"Kanada berdiri pada tahun seribu delapan ratus enam puluh tujuh, setelah disahkannya undang-undang Konfederasi.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = g2p(text)\n",
    "text = g2p_post(text)\n",
    "sequence = np.array(text_to_sequence(text, ['basic_cleaners']))[None, :]\n",
    "sequence = torch.autograd.Variable(\n",
    "    torch.from_numpy(sequence)).long()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decode text input and plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "mel_outputs, mel_outputs_postnet, _, alignments = model.inference(sequence)\n",
    "plot_data((mel_outputs.float().data.cpu().numpy()[0],\n",
    "           mel_outputs_postnet.float().data.cpu().numpy()[0],\n",
    "           alignments.float().data.cpu().numpy()[0].T))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Synthesize audio from spectrogram using WaveGlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    y_g_hat = generator(mel_outputs_postnet)\n",
    "    audio = y_g_hat.squeeze()\n",
    "    audio = audio * MAX_WAV_VALUE\n",
    "    audio = audio.cpu().numpy().astype(\"int16\")\n",
    "ipd.Audio(audio, rate=hparams.sampling_rate)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
